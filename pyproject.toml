[project]
name = "llm-twin"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.11"
dependencies = [
    "beautifulsoup4>=4.13.5",
    "chromedriver-autoinstaller>=0.6.4",
    "click>=8.2.1",
    "datasets>=4.0.0",
    "fastapi>=0.115.8",
    "html2text>=2025.4.15",
    "jinja2>=3.1.6",
    "langchain>=0.3.27",
    "langchain-community>=0.3.21",
    "langchain-openai>=0.3.33",
    "loguru>=0.7.3",
    "numpy>=1.26.4",
    "poethepoet>=0.37.0",
    "pymongo>=4.15.0",
    "qdrant-client>=1.12.1",
    "rich>=14.1.0",
    "sagemaker>=2.251.1",
    "selenium>=4.35.0",
    "sentence-transformers>=5.1.0",
    "tiktoken>=0.11.0",
    "torch>=2.8.0",
    "uvicorn>=0.35.0",
    "webdriver-manager>=4.0.2",
    "zenml[server]>=0.84.3",
]

[dependency-groups]
aws = [
    "sagemaker>=2.251.1",
]


[tool.poe.tasks]
## SageMaker
create-sagemaker-role = "uv run python -m llm_engineering.infrastructure.aws.roles.create_sagemaker_role"
create-sagemaker-execution-role = "uv run python -m llm_engineering.infrastructure.aws.roles.create_execution_role"
deploy-inference-endpoint = "uv run python -m llm_engineering.infrastructure.aws.deploy.huggingface.run"
test-sagemaker-endpoint = "uv run python -m llm_engineering.model.inference.test"
delete-inference-endpoint = "uv run python -m llm_engineering.infrastructure.aws.deploy.delete_sagemaker_endpoint"

## inference
run-inference-ml-service = "uv run uvicorn tools.ml_service:app --host 0.0.0.0 --port 8000 --reload"
call-inference-ml-service = "curl -X POST 'http://127.0.0.1:8000/rag' -H 'Content-Type: application/json' -d '{\"query\": \"Create an article about the strengths and weaknesses of 4-4-2 formation.\"}'"
